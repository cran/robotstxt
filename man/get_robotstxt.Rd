% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/parse_robotstxt.R
\name{get_robotstxt}
\alias{get_robotstxt}
\title{downloading robots.txt file}
\usage{
get_robotstxt(domain, warn = TRUE, force = FALSE, user_agent = NULL)
}
\arguments{
\item{domain}{domain from which to download robots.txt file}

\item{warn}{warn about being unable to download domain/robots.txt because of}

\item{force}{if TRUE instead of using possible cached results te function will
re-download the robotstxt file
HTTP resposne status 404. If this happens,}

\item{user_agent}{HTTP user-agent string to be used to retireve robots.txt file
from domain}
}
\description{
downloading robots.txt file
}
